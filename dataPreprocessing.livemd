<!-- livebook:{"file_entries":[{"file":{"file_system_id":"local","file_system_type":"local","path":"/Users/qianqian/tpcDataAnalysis/Data/answers-be5f350-2025-03-21 14_42_16.csv"},"name":"answers-be5f350-2025-03-21_14_42_16.csv","type":"file"},{"file":{"file_system_id":"local","file_system_type":"local","path":"/Users/qianqian/tpcDataAnalysis/Data/events-be5f350-2025-03-21 14_45_42.csv"},"name":"events-be5f350-2025-03-21_14_45_42.csv","type":"file"},{"file":{"file_system_id":"local","file_system_type":"local","path":"/Users/qianqian/tpcDataAnalysis/Data/participation-be5f350-2025-03-21 14_43_53.csv"},"name":"participation-be5f350-2025-03-21_14_43_53.csv","type":"file"}]} -->

# DataAnalysis

```elixir
Mix.install([
  {:req, "~> 0.4.8"},
  {:explorer, "~> 0.8.0"},
  {:kino_explorer, "~> 0.1.18"},
  {:vega_lite, "~> 0.1.8"},
  {:kino_vega_lite, "~> 0.1.3"},
  {:tzdata, "~> 1.1"}
])
```

## Section

```elixir
require Explorer.DataFrame, as: DF
require Explorer.Series, as: Series
require VegaLite, as: Vl
```

For simplicity and flexibility purposes, let's define the file paths to all the csv files that is needed.

```elixir
defmodule Constants do
  @answers_file_path "/Users/qianqian/tpcDataAnalysis/Data/answers-be5f350-2025-03-21 14_42_16.csv"
  @events_file_path "/Users/qianqian/tpcDataAnalysis/Data/events-be5f350-2025-03-21 14_45_42.csv"
  @participation_file_path "/Users/qianqian/tpcDataAnalysis/Data/participation-be5f350-2025-03-21 14_43_53.csv"
  
  def get_answers_file_path, do: @answers_file_path
  def get_events_file_path, do: @events_file_path
  def get_participation_file_path, do: @participation_file_path
end
```

## Session 1: First Inspection of csv Data

Initial inspection into **answers.csv**.

```elixir
answers_df = DF.from_csv!(Constants.get_answers_file_path())
IO.inspect(answers_df)
```

Throughout the online course, students were asked to answer some questionnaires. Initial questionnaire to understand the basic information of the participants (such as the country of origin, gender, knowledge level of technology, etc). Other questionnaire are also included halfway through the course, to understand how they have being doing it. Lastly a final questionnaire is included to ask regarding their final experience. This csv file contains all the answers responded by the participants.

Data description goes here

1. What is this data about in general
2. What is the average number of questions per activity (ID de Actividad)
3. What are the most common types of questions
4. Which question has the highest number of responses
5. which question has the lowest number of responses

<!-- livebook:{"break_markdown":true} -->

We realised that not all the questions are answered by the students. Hence we discard them.

```elixir
#remove null data
answers_df = DF.filter_with(answers_df, fn answers_df -> Explorer.Series.is_not_nil(answers_df["Texto de la respuesta"]) end)
IO.inspect(answers_df)
```

```elixir
answers_df = DF.discard(answers_df, ["Texto de la respuesta"])
```

```elixir
student_age_df = DF.filter_with(answers_df, fn answers_df -> Explorer.Series.equal(answers_df["Texto de la pregunta"], "¿Cuál es su edad?") end)

grouped_age_df =
  student_age_df
    |> DF.group_by("Selección en la respuesta")
    |> DF.summarise_with(&[count: Series.count(&1["Selección en la respuesta"])])

#Draw bar chart 
bar_chart = 
Vl.new(width: 600, height: 400)
|> Vl.data_from_values(grouped_age_df)
|> Vl.mark(:bar, clip: true)
|> Vl.encode_field(:x, "Selección en la respuesta", title: "Age Range", axis: [label_angle: 0])
|> Vl.encode_field(:y, "count",
  type: :quantitative,
  title: "Count",
  scale: [domain: [0, 28]]
)

Kino.VegaLite.new(bar_chart)
```

```elixir
#see example of ome 
participant_questions = DF.filter_with(answers_df, fn answers_df -> Explorer.Series.equal(answers_df["Código de participante"], "a12") end)
group_question_df =
      participant_questions
        |> DF.group_by("ID Actividad")
        |> DF.summarise_with(&[count: Series.count(&1["ID Actividad"])])
        |> DF.filter(count == 1)
```

```elixir
participant_questions = DF.filter_with(participant_questions, fn participant_questions -> Explorer.Series.equal(participant_questions["ID de pregunta"], "032c9707-6194-42b6-90f7-6e6692798560") end)
```

```elixir
questions_df = DF.distinct(answers_df, ["Texto de la pregunta"])
column_values = DF.to_series(questions_df)
column_values = Series.to_list(column_values["Texto de la pregunta"])
column_values = ["Participant Code" | column_values]
columns_map = Map.new(column_values, fn col -> {col, []} end)
#new_df = DF.new(columns_map)

{:ok, new_df_agent} = Agent.start(fn -> DF.new(columns_map) end)

participants_list = DF.select(answers_df, ["Código de participante"])
participants_list = DF.distinct(participants_list, ["Código de participante"])
participants_list = DF.to_rows(participants_list)

Enum.each(participants_list, fn row -> 
  current_participant_code = row["Código de participante"]
  #Get the questions answers by the participants
  participant_questions = DF.filter_with(answers_df, fn answers_df -> Explorer.Series.equal(answers_df["Código de participante"], current_participant_code) end)
  IO.puts("Participants with code #{current_participant_code} has answered #{DF.n_rows(participant_questions)} questions.")
  participant_questions_map = DF.to_rows(participant_questions)
  #iterate through the questions
  Enum.each(participant_questions_map, fn question ->
    current_answer = question["Selección en la respuesta"]
    current_question = question["Texto de la pregunta"]
    # Create a row 
    result_map = Map.new(column_values, fn col -> 
        if (col == current_question) do
          {col, [current_answer]}
        else if (col == "Participant Code") do
          {col, [current_participant_code]}
        else 
          {col, [:nil]}
        end
        end
      end)
    df2 = DF.new(result_map)
    #DF.concat_rows(question, df2)
    Agent.update(new_df_agent, fn df -> DF.concat_rows(df, df2) end)
    end)
  end)

new_df = Agent.get(new_df_agent, & &1)
IO.inspect(new_df)

```

## Inspection into events.csv

```elixir
events_df = DF.from_csv!(Constants.get_events_file_path())
IO.inspect(events_df)
```

From the this dataset, we can see that it contains the time of when the student enteres and exits the platform (recorded in the column of "Ocurrío en"). With this piece of information we can generate some interesting data that can be useful for our model:

1. Each time a student enters the platform, how long do they stay? Longer time on the platform may refer to better student engagement
2. How frequently does a student enters to the platform? As in, the number of "entered" event. A higher frequency may reflect to higher engagement level

Let's generate the data from the 1st point. To start with let's observe the data type of each column.

```elixir
DF.dtypes(events_df)
```

We can see that the "Ocurrío en" column contains a string datatype.

In Elixir, there is an interesting module DateTime that represents a special data structure for date and time. More interestingly, there is a built-in function that directly computes the time differences in seconds. To generate this data structure, we need different information such as year, month, date, time, timezone, etc. So what we need to do first is to gather all this information from the string. Hence, a special module is created, called "TimeParser"

```elixir
defmodule TimeParser do
  @monthRegex ~r/^\d{4}-(\d{2})-\d{2}/
  @dateRegex ~r/^\d{4}-\d{2}-(\d{2})/
  @yearRegex ~r/^(\d{4})-\d{2}-\d{2}/
  @hourRegex ~r/(\d{2}):\d{2}:\d{2}/
  @minuteRegex ~r/\d{2}:(\d{2}):\d{2}/
  @secondRegex ~r/\d{2}:\d{2}:(\d{2}).\d/
  @microsecondRegex ~r/\d{2}:\d{2}:\d{2}.(\d{6})/
  @timezoneRegex ~r/\s[A-Za-z]+\s([\w\/]+)$/
  
  def get_month(time_text) do
    month_result = Regex.run(@monthRegex, time_text)
    month_result = Enum.at(month_result, 1)
    String.to_integer(month_result)
  end

  def get_date(time_text) do
    date_result = Regex.run(@dateRegex, time_text)
    date_result = Enum.at(date_result, 1)
    String.to_integer(date_result)
  end

  def get_year(time_text) do
    year_result = Regex.run(@yearRegex, time_text)
    year_result = Enum.at(year_result, 1)
    String.to_integer(year_result)
  end

  def get_hour(time_text) do
    hour_result = Regex.run(@hourRegex, time_text)
    hour_result = Enum.at(hour_result, 1)
    String.to_integer(hour_result)
  end

  def get_minute(time_text) do
    minute_result = Regex.run(@minuteRegex, time_text)
    minute_result = Enum.at(minute_result, 1)
    String.to_integer(minute_result)
  end

  def get_second(time_text) do
    second_result = Regex.run(@secondRegex, time_text)
    second_result = Enum.at(second_result, 1)
    String.to_integer(second_result)
  end

  def get_timezone(time_text) do
    timezone_result = Regex.run(@timezoneRegex, time_text)
    Enum.at(timezone_result, 1)
  end

  def get_microsecond(time_text) do
    microsecond_result = Regex.run(@microsecondRegex, time_text)
    microsecond_result = Enum.at(microsecond_result, 1)
    String.to_integer(microsecond_result)
  end
end

#IO.puts(TimeParser.get_timezone("2025-03-21 12:16:33.518269+01:00 CET Europe/Madrid"))
```

```elixir
#define a function to determine the time differences in seconds
generate_dateTime_diff_from_str = fn str1, str2 ->
  entered_date = Date.new!(TimeParser.get_year(str1), TimeParser.get_month(str1), TimeParser.get_date(str1))
  entered_time = Time.new!(TimeParser.get_hour(str1), TimeParser.get_minute(str1), TimeParser.get_second(str1), TimeParser.get_microsecond(str1))  
  entered_dateTime = DateTime.new!(entered_date, entered_time, TimeParser.get_timezone(str1), Tzdata.TimeZoneDatabase)
  #get the exited date
  exited_date = Date.new!(TimeParser.get_year(str2), TimeParser.get_month(str2), TimeParser.get_date(str2))
  exited_time = Time.new!(TimeParser.get_hour(str2), TimeParser.get_minute(str2), TimeParser.get_second(str2), TimeParser.get_microsecond(str2))
  exited_dateTime = DateTime.new!(exited_date, exited_time, TimeParser.get_timezone(str2), Tzdata.TimeZoneDatabase)

  DateTime.diff(entered_dateTime, exited_dateTime)
end

# Convert DataFrame to a list of maps
events_map_list = DF.to_rows(events_df)

# Process every 2 rows together
new_rows =
  events_map_list
  |> Enum.chunk_every(2)
  |> Enum.flat_map(fn
    [row1, row2] ->
      time_diff = generate_dateTime_diff_from_str.(row2["Ocurrió en"], row1["Ocurrió en"])
      IO.puts(time_diff)
      [
        Map.put(row1, "time differences (sec)", time_diff),
        Map.put(row2, "time differences (sec)", time_diff)
      ]
  end)

# Convert back to DataFrame
event_df =DF.new(new_rows)

#IO.inspect(new_df)

```

Let's now focus on the second piece of information that we want to gather. That is, the "entered" frequency. We will be generating a new dataset to store this piece of information.

```elixir
participants_list = DF.select(events_df, ["Participante"])
participants_list = DF.distinct(participants_list, ["Participante"])
participants_list = DF.to_rows(participants_list)
#Process each row
new_rows = 
  participants_list
  |> Enum.map(fn
    participant-> 
      # filter the database based on participants name + "entered" event
      participant_name = participant["Participante"]
      participant_data =
        events_df
          |> DF.filter_with(fn events_df -> Explorer.Series.equal(events_df["Participante"], participant_name) end)
          |> DF.filter_with(fn events_df -> Explorer.Series.equal(events_df["Tipo de evento"], "entered") end)
      frequency = DF.n_rows(participant_data)
      # 
      Map.put(participant,"Entered frequency", frequency)
  end)

frequency_df = DF.new(new_rows)
```

Initial inspection into **participation.csv**

```elixir
participation_df = DF.from_csv!(Constants.get_participation_file_path())
IO.inspect(participation_df)
```

This dataset contains very important information that we could use directly. Such as, time following the course, number of video reproduced, boolean variable to represent whether a course has been studied at least 75%, etc. However, there is one more information that we could calculate. That is, how long a student has been enrolled up until today. this information can be usefull for the following insight:

1. If a student has been enrolled for a long time but has very low participation (e.g. low number of video has been watched), they might be at risk of dropping out.
2. Students who have been enrolled longer might show better engagement.
3. If most students who stay enrolled for a long time don’t complete the course, it may indicate the course is not engaging or is too difficult.

```elixir
#current time in UTC
current_time = DateTime.now!("Etc/UTC") 
#convert current time to CET
current_time = DateTime.shift_zone!(current_time, "Europe/Madrid", Tzdata.TimeZoneDatabase)

# Convert DataFrame to a list of maps
participation_map_list = DF.to_rows(participation_df)
# Process every rows 
new_rows =
  participation_map_list
  |> Enum.map(fn
    row -> 
      # compute duration in second from the first enrollment date until now 
      enrolment_duration = generate_dateTime_diff_from_str.(DateTime.to_string(current_time), row["Hora comienzo curso"])
      # recalculate the duration into n days for better interpretation
      n_days = round(enrolment_duration / 86400)
      
      row
      |>Map.put("Enrolment duration (sec)", enrolment_duration)
      |>Map.put("Enrolment duration (days)", n_days)
  end)

# Convert back to DataFrame
participation_df = DF.new(new_rows)
```

<!-- livebook:{"offset":13651,"stamp":{"token":"XCP.SS5BCPo6nacxFAPVsSmnn7LajhYWGXLK8jn6sRg-Y-43eUzsNxWnLydz_sBh8Mdrv2dAo51PB110hknVyOwTG3AcoYUGo3Vp2AVn-w","version":2}} -->
